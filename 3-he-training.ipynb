{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINTS_PATH = 'models/checkpoints'\n",
    "MODEL_ARCHITECTURE_PATH = 'models/model_architecture'\n",
    "MODEL_WEIGHTS_PATH = 'models/model_weights'\n",
    "MODEL_HISTORY_PATH = 'models/model_history'\n",
    "MODEL_SERVING_PATH = 'models/tf_saved_models/1'\n",
    "\n",
    "#IMAGE_SIZE = 256\n",
    "IMAGE_SIZE = 300\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "LABELS = ['No', 'Yes']\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 15\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/2021_STUDY/HE/train'\n",
    "val_dir = 'data/2021_STUDY/HE/eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 10, 10, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 23,852,065\n",
      "Trainable params: 317,473\n",
      "Non-trainable params: 23,534,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_model(input_shape, learning_rate=1e-4):\n",
    "    pretrained_model = ResNet50(\n",
    "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=input_shape,\n",
    "        include_top=False\n",
    "    )\n",
    "    # freeze the the pre-trained model\n",
    "    #pretrained_model.trainable = False\n",
    "    for layer in pretrained_model.layers:\n",
    "        if isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    model = Sequential([\n",
    "        pretrained_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(rate=0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(rate=0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model(\n",
    "    IMAGE_SHAPE,\n",
    "    learning_rate=LEARNING_RATE\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20210 images belonging to 2 classes.\n",
      "Found 4030 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "1346/1347 [============================>.] - ETA: 9s - loss: 0.3881 - acc: 0.8252 Epoch 1/20\n",
      "1347/1347 [==============================] - 13619s 10s/step - loss: 0.3880 - acc: 0.8252 - val_loss: 0.3114 - val_acc: 0.8692\n",
      "Epoch 2/20\n",
      "1346/1347 [============================>.] - ETA: 9s - loss: 0.2260 - acc: 0.9109 Epoch 1/20\n",
      "1347/1347 [==============================] - 13128s 10s/step - loss: 0.2259 - acc: 0.9109 - val_loss: 0.3134 - val_acc: 0.8624\n",
      "Epoch 3/20\n",
      "1346/1347 [============================>.] - ETA: 9s - loss: 0.1535 - acc: 0.9432 Epoch 1/20\n",
      "1347/1347 [==============================] - 13083s 10s/step - loss: 0.1535 - acc: 0.9432 - val_loss: 0.3095 - val_acc: 0.8726\n",
      "Epoch 4/20\n",
      "1346/1347 [============================>.] - ETA: 9s - loss: 0.1126 - acc: 0.9609 Epoch 1/20\n",
      "1347/1347 [==============================] - 13158s 10s/step - loss: 0.1128 - acc: 0.9608 - val_loss: 0.3438 - val_acc: 0.8789\n",
      "Epoch 5/20\n",
      "1346/1347 [============================>.] - ETA: 14s - loss: 0.0801 - acc: 0.9717Epoch 1/20\n",
      "1347/1347 [==============================] - 19788s 15s/step - loss: 0.0802 - acc: 0.9716 - val_loss: 0.3801 - val_acc: 0.8697\n",
      "Epoch 6/20\n",
      "1346/1347 [============================>.] - ETA: 11s - loss: 0.0623 - acc: 0.9790Epoch 1/20\n",
      "1347/1347 [==============================] - 15543s 12s/step - loss: 0.0623 - acc: 0.9790 - val_loss: 0.3628 - val_acc: 0.8945\n",
      "Epoch 7/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0529 - acc: 0.9824 Epoch 1/20\n",
      "1347/1347 [==============================] - 11899s 9s/step - loss: 0.0529 - acc: 0.9824 - val_loss: 0.3554 - val_acc: 0.8958\n",
      "Epoch 8/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0446 - acc: 0.9854 Epoch 1/20\n",
      "1347/1347 [==============================] - 11855s 9s/step - loss: 0.0446 - acc: 0.9854 - val_loss: 0.3935 - val_acc: 0.8955\n",
      "Epoch 9/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0352 - acc: 0.9890 Epoch 1/20\n",
      "1347/1347 [==============================] - 11844s 9s/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.3796 - val_acc: 0.8903\n",
      "Epoch 10/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0277 - acc: 0.9907 Epoch 1/20\n",
      "1347/1347 [==============================] - 11970s 9s/step - loss: 0.0277 - acc: 0.9907 - val_loss: 0.3737 - val_acc: 0.9090\n",
      "Epoch 11/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0290 - acc: 0.9915 Epoch 1/20\n",
      "1347/1347 [==============================] - 12231s 9s/step - loss: 0.0290 - acc: 0.9915 - val_loss: 0.4277 - val_acc: 0.8980\n",
      "Epoch 12/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0249 - acc: 0.9926 Epoch 1/20\n",
      "1347/1347 [==============================] - 11916s 9s/step - loss: 0.0249 - acc: 0.9926 - val_loss: 0.4620 - val_acc: 0.8893\n",
      "Epoch 13/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0234 - acc: 0.9936 Epoch 1/20\n",
      "1347/1347 [==============================] - 11942s 9s/step - loss: 0.0233 - acc: 0.9936 - val_loss: 0.4419 - val_acc: 0.9060\n",
      "Epoch 14/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0162 - acc: 0.9945 Epoch 1/20\n",
      "1347/1347 [==============================] - 12059s 9s/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.5660 - val_acc: 0.8985\n",
      "Epoch 15/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0170 - acc: 0.9946 Epoch 1/20\n",
      "1347/1347 [==============================] - 11683s 9s/step - loss: 0.0170 - acc: 0.9947 - val_loss: 0.4635 - val_acc: 0.8993\n",
      "Epoch 16/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0127 - acc: 0.9960 Epoch 1/20\n",
      "1347/1347 [==============================] - 11590s 9s/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.5390 - val_acc: 0.8920\n",
      "Epoch 17/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0161 - acc: 0.9949 Epoch 1/20\n",
      "1347/1347 [==============================] - 11608s 9s/step - loss: 0.0161 - acc: 0.9949 - val_loss: 0.5012 - val_acc: 0.9012\n",
      "Epoch 18/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0119 - acc: 0.9964 Epoch 1/20\n",
      "1347/1347 [==============================] - 11763s 9s/step - loss: 0.0119 - acc: 0.9964 - val_loss: 0.5114 - val_acc: 0.9012\n",
      "Epoch 19/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0115 - acc: 0.9959 Epoch 1/20\n",
      "1347/1347 [==============================] - 11657s 9s/step - loss: 0.0115 - acc: 0.9959 - val_loss: 0.5668 - val_acc: 0.8958\n",
      "Epoch 20/20\n",
      "1346/1347 [============================>.] - ETA: 8s - loss: 0.0101 - acc: 0.9970 Epoch 1/20\n",
      "1347/1347 [==============================] - 11770s 9s/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.4552 - val_acc: 0.9104\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "def train(model, train_dir, val_dir, input_shape,\n",
    "          batch_size=15,\n",
    "          epochs=50):\n",
    "    \"\"\"\n",
    "    Train a Keras model usin batches.\n",
    "    \n",
    "    Arguments:\n",
    "      model -- Keras model to train.\n",
    "      train_gen -- Python generator to retrieve the training samples by batches.\n",
    "      eval_gen -- Python generator to retrieve the validation samples by batches.\n",
    "      input_shape -- tuple indicating the image shape (high, width, num_channels).\n",
    "      batch_size -- number of images to retrieve in each batch.\n",
    "      epochs -- numbers of time that the model have to train the whole dataset.\n",
    "    \n",
    "    Returns:\n",
    "      model -- Keras model trained.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(MODEL_CHECKPOINTS_PATH):\n",
    "        os.mkdir(MODEL_CHECKPOINTS_PATH)\n",
    "    filepath = 'models/checkpoints/weights-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='val_acc',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='max'\n",
    "    )\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=input_shape,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=16\n",
    "    )\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "    val_gen = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=input_shape,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=16\n",
    "    )\n",
    "    train_steps = train_gen.n // train_gen.batch_size\n",
    "    validation_steps = val_gen.n // val_gen.batch_size\n",
    "    return model.fit_generator(\n",
    "        train_gen, \n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=val_gen,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "\n",
    "history = train(\n",
    "    model,\n",
    "    train_dir,\n",
    "    val_dir,\n",
    "    (IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model(model):\n",
    "    \"\"\"\n",
    "    Saves a Keras model creating the following file structure:\n",
    "      model_architecture -- neural network architecture saved as JSON and Yaml files.\n",
    "      model_history -- model training history saved as Pickle binary object.\n",
    "      model_weights -- model weights saved in HDF5 format.\n",
    "    \n",
    "    Arguments:\n",
    "      model -- Keras model to train.\n",
    "    \"\"\"\n",
    "    # Saves the whole model\n",
    "    model_path = 'models/resnet-{}.h5'.format(IMAGE_SIZE)\n",
    "    model.save(model_path)\n",
    "    \n",
    "    if not os.path.isdir(MODEL_ARCHITECTURE_PATH):\n",
    "        os.mkdir(MODEL_ARCHITECTURE_PATH)\n",
    "\n",
    "    # Saves the model architecture as JSON file\n",
    "    json_path = '{}/resnet-{}-arc.json'.format(MODEL_ARCHITECTURE_PATH, IMAGE_SIZE)\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "\n",
    "    # Saves the model architecture as YAML file\n",
    "    yaml_path = '{}/resnet-{}-arc.yml'.format(MODEL_ARCHITECTURE_PATH, IMAGE_SIZE)\n",
    "    with open(yaml_path, \"w\") as yaml_file:\n",
    "        yaml_file.write(model.to_yaml())\n",
    "        \n",
    "    print(\"Model architecture saved as:\\n\\t- {}\\n\\t- {}\".format(json_path, yaml_path))\n",
    "        \n",
    "    if not os.path.isdir(MODEL_WEIGHTS_PATH):\n",
    "        os.mkdir(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "    # Saves the model weights\n",
    "    weight_path = '{}/resnet-{}-wt.h5'.format(MODEL_WEIGHTS_PATH, IMAGE_SIZE)\n",
    "    model.save_weights(\n",
    "        filepath=weight_path,\n",
    "        overwrite=True\n",
    "    )\n",
    "    \n",
    "    print(\"Model weights saved as {}.\".format(weight_path))\n",
    "    \n",
    "    if not os.path.isdir(MODEL_HISTORY_PATH):\n",
    "        os.mkdir(MODEL_HISTORY_PATH)\n",
    "\n",
    "    # Saves the history model\n",
    "    history_path = '{}/resnet-{}-history'.format(MODEL_HISTORY_PATH, IMAGE_SIZE)\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(model.history.history, f)\n",
    "        \n",
    "    print(\"Model history saved as {}.\".format(history_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json, model_from_yaml\n",
    "\n",
    "def load_model(arc_path, weights_path=None):\n",
    "    \"\"\"\n",
    "    Loads a model which was saved with save_model function.\n",
    "    \n",
    "    Arguments:\n",
    "      arc_path -- path to the model architecture file (JSON or YAML).\n",
    "      weights_path -- path to the model weights file (HDF5).\n",
    "      \n",
    "    Returns:\n",
    "      model -- loaded Keras model.\n",
    "    \"\"\"\n",
    "    file = open(arc_path, 'r')\n",
    "    content = file.read()\n",
    "    model = None\n",
    "    \n",
    "    if '.json' in arc_path:\n",
    "        model = model_from_json(content)\n",
    "    elif '.yml' in arc_path:\n",
    "        model = model_from_yaml(content)\n",
    "    \n",
    "    if weights_path is not None:\n",
    "        model.load_weights(weights_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture saved as:\n",
      "\t- models/model_architecture/resnet-300-arc.json\n",
      "\t- models/model_architecture/resnet-300-arc.yml\n",
      "Model weights saved as models/model_weights/resnet-300-wt.h5.\n",
      "Model history saved as models/model_history/resnet-300-history.\n"
     ]
    }
   ],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Model loaded from a JSON file.\n"
     ]
    }
   ],
   "source": [
    "json_path = '{}/resnet-{}-arc.json'.format(MODEL_ARCHITECTURE_PATH, IMAGE_SIZE)\n",
    "saved_model = load_model(json_path)\n",
    "\n",
    "print(\"Keras Model loaded from a JSON file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://models/HE/resnet-300.h5 [Content-Type=application/octet-stream]...\n",
      "Copying file://models/HE/model_architecture/resnet-300-arc.yml [Content-Type=application/octet-stream]...\n",
      "Copying file://models/HE/model_architecture/resnet-300-arc.json [Content-Type=application/json]...\n",
      "Copying file://models/HE/model_history/resnet-300-history [Content-Type=application/octet-stream]...\n",
      "Copying file://models/HE/model_weights/resnet-300-wt.h5 [Content-Type=application/octet-stream]...\n",
      "\\ [5/5 files][185.4 MiB/185.4 MiB] 100% Done  15.6 MiB/s ETA 00:00:00           \n",
      "Operation completed over 5 objects/185.4 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m mv gs://ex-vivo-confocal/models/HE gs://ex-vivo-confocal/models/HE_back\n",
    "!gsutil -m cp -r models/HE gs://ex-vivo-confocal/models/HE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
